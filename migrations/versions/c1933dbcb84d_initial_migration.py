"""Initial migration

Revision ID: c1933dbcb84d
Revises: 
Create Date: 2026-01-04 00:30:23.976008

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'c1933dbcb84d'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('documents',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('filename', sa.String(length=255), nullable=False),
    sa.Column('original_filename', sa.String(length=255), nullable=False),
    sa.Column('file_size', sa.BigInteger(), nullable=False),
    sa.Column('mime_type', sa.String(length=100), nullable=False),
    sa.Column('storage_key', sa.String(length=500), nullable=False),
    sa.Column('checksum', sa.String(length=64), nullable=False),
    sa.Column('uploaded_by', sa.String(length=100), nullable=True),
    sa.Column('uploaded_at', sa.DateTime(), nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('storage_key')
    )
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.create_index('idx_documents_checksum', ['checksum'], unique=False)
        batch_op.create_index('idx_documents_uploaded_at', ['uploaded_at'], unique=False)
        batch_op.create_index('idx_documents_uploaded_by', ['uploaded_by'], unique=False)

    op.create_table('processing_jobs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('job_type', sa.String(length=50), nullable=False),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('priority', sa.Integer(), nullable=True),
    sa.Column('celery_task_id', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('retry_count', sa.Integer(), nullable=True),
    sa.Column('max_retries', sa.Integer(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('error_trace', sa.Text(), nullable=True),
    sa.Column('options', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('processing_jobs', schema=None) as batch_op:
        batch_op.create_index('idx_jobs_celery_task_id', ['celery_task_id'], unique=False)
        batch_op.create_index('idx_jobs_created_at', ['created_at'], unique=False)
        batch_op.create_index('idx_jobs_document_id', ['document_id'], unique=False)
        batch_op.create_index('idx_jobs_job_type', ['job_type'], unique=False)
        batch_op.create_index('idx_jobs_status', ['status'], unique=False)

    op.create_table('job_results',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('result_type', sa.String(length=50), nullable=False),
    sa.Column('result_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('output_file_key', sa.String(length=500), nullable=True),
    sa.Column('file_size', sa.BigInteger(), nullable=True),
    sa.Column('mime_type', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.CheckConstraint('result_data IS NOT NULL OR output_file_key IS NOT NULL', name='ck_result_has_data'),
    sa.ForeignKeyConstraint(['job_id'], ['processing_jobs.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('job_id', 'result_type', name='uq_job_result_type')
    )
    with op.batch_alter_table('job_results', schema=None) as batch_op:
        batch_op.create_index('idx_results_job_id', ['job_id'], unique=False)
        batch_op.create_index('idx_results_result_type', ['result_type'], unique=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('job_results', schema=None) as batch_op:
        batch_op.drop_index('idx_results_result_type')
        batch_op.drop_index('idx_results_job_id')

    op.drop_table('job_results')
    with op.batch_alter_table('processing_jobs', schema=None) as batch_op:
        batch_op.drop_index('idx_jobs_status')
        batch_op.drop_index('idx_jobs_job_type')
        batch_op.drop_index('idx_jobs_document_id')
        batch_op.drop_index('idx_jobs_created_at')
        batch_op.drop_index('idx_jobs_celery_task_id')

    op.drop_table('processing_jobs')
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.drop_index('idx_documents_uploaded_by')
        batch_op.drop_index('idx_documents_uploaded_at')
        batch_op.drop_index('idx_documents_checksum')

    op.drop_table('documents')
    # ### end Alembic commands ###
